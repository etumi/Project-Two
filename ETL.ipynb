{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Data For Dashbord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt \n",
    "import requests\n",
    "from config import *\n",
    "from pprint import pprint\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Airpollution Data for U.S.A from 2000 - 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV \n",
    "data = pd.read_csv(\"Resources/pollution_us_2000_2016.csv\")\n",
    "# Pollution in the U.S. since 2000\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data = data.drop_duplicates()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['State'] != 'Country Of Mexico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed columns from the dataframe\n",
    "pollution_data = data2.drop(columns=['State Code', 'County Code', 'Site Num', 'Address','County', 'City', 'NO2 Units','NO2 1st Max Value', 'NO2 1st Max Hour', 'O3 Units','O3 1st Max Value', 'O3 1st Max Hour', 'SO2 Units', 'SO2 1st Max Value', 'SO2 1st Max Hour', 'CO Units','CO 1st Max Value', 'CO 1st Max Hour'], axis = 1)\n",
    "# Conver Date Local to Years\n",
    "pollution_data['Date Local'] = pd.to_datetime(pollution_data['Date Local'], format='%Y/%m/%d').dt.year\n",
    "\n",
    "#weather_data.head()\n",
    "pollution_data = pollution_data.rename(columns = {\"Date Local\": \"Year\"})\n",
    "pollution_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# States Mentioned in the data \n",
    "states = list(data2['State'].unique())\n",
    "print(len(states))\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    #AQI_mean[AQI_mean['State'] == state]\n",
    "    print(state)\n",
    "    print(weather_data[pollution_data['State'] == state]['Year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AQI Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AQI Mean for the State Across the years \n",
    "AQI_df = pollution_data[['State','Year','NO2 AQI','O3 AQI','SO2 AQI','CO AQI']]\n",
    "#make all columns lower case and remove AQI\n",
    "columnsX = list(AQI_df.columns)\n",
    "columnsX = [x.lower() for x in columnsX]\n",
    "columnsX = [x.replace(' aqi', '') for x in columnsX]\n",
    "AQI_df.columns = columnsX\n",
    "\n",
    "AQI_mean = AQI_df.groupby(['state', 'year']).mean()\n",
    "AQI_mean = AQI_mean.reset_index()\n",
    "\n",
    "AQI_mean['id'] = AQI_mean.index\n",
    "\n",
    "AQI_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Data to PgAdmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql://postgres:{AWS_password}@database-1.cft8wszdkeh0.us-east-2.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "AQI_mean.to_sql(name=\"pollution\",con=engine, if_exists=\"replace\", index=False) #Pollution Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "    con.execute('ALTER TABLE \"pollution\" ADD PRIMARY KEY (id);')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CO2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Co2 database\n",
    "CO2_data = pd.read_csv(\"Resources/CO2 DB_1.csv\");\n",
    "CO2_data = CO2_data.set_index('year')\n",
    "CO2_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transpose Data\n",
    "CO2_data_tranposed = CO2_data.T\n",
    "CO2_data_tranposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put each row into a tupple and then a list. Then add to a larger list\n",
    "CO2_data_list = []\n",
    "for i in CO2_data_tranposed.itertuples():\n",
    "    state_data = list(i)\n",
    "    #print(i) \n",
    "    #print(test)\n",
    "    CO2_data_list.append(state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each states data into a dictionary that can go into the dataframe\n",
    "df_array = []\n",
    "#year = 1990\n",
    "for state in CO2_data_list:\n",
    "    year = 1990\n",
    "    for i, x in enumerate(state):\n",
    "        if i == 0:\n",
    "            curr_state = x\n",
    "        else:\n",
    "            dict = {}\n",
    "            dict['State'] = curr_state\n",
    "    #         year = 1990\n",
    "            dict['Year'] = year\n",
    "            dict['CO2 AQI'] = x\n",
    "            year += 1\n",
    "            df_array.append(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe\n",
    "CO2_df = pd.DataFrame(df_array)\n",
    "CO2_df = CO2_df.replace('District of Columbia', 'District Of Columbia')\n",
    "\n",
    "#CO2_df = CO2_df.reset_index()\n",
    "\n",
    "columnsX = list(CO2_df.columns)\n",
    "columnsX = [x.lower() for x in columnsX]\n",
    "columnsX = [x.replace(' aqi', '') for x in columnsX]\n",
    "CO2_df.columns = columnsX\n",
    "\n",
    "CO2_df['id'] = CO2_df.index\n",
    "\n",
    "CO2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Data to PgAdmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql://postgres:{AWS_password}@database-1.cft8wszdkeh0.us-east-2.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "CO2_df.to_sql(name=\"co2_aqi\",con=engine, if_exists=\"replace\", index=False) #CO2 AQI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "    con.execute('ALTER TABLE \"co2_aqi\" ADD PRIMARY KEY (id);')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Kaggle and CO2 Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "frames = [CO2_df, AQI_mean]\n",
    "\n",
    "#result = pd.concat(frames, axis=0, join='outer', ignore_index=True, keys=None, sort=True, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "#result = CO2_df.join(AQI_mean, on=['State', 'Year'])\n",
    "\n",
    "#result = pd.merge(CO2_df, AQI_mean, left_on=['State', 'Year'] , right_index=False, how='CO2_df', sort=False);\n",
    "\n",
    "AQI_df = pd.merge(CO2_df, AQI_mean,  how='left', left_on=['State','Year'], right_on = ['State','Year'])\n",
    "\n",
    "AQI_df \n",
    "#result[result['State'] == \"Alabama\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Data to PgAdmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#engine = create_engine(f\"postgresql://postgres:{AWS_password}@database-1.cft8wszdkeh0.us-east-2.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "#AQI_df.to_sql(name=\"All_AQI\",con=engine, if_exists=\"replace\", index=False) #Full AQI Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Average Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 states with highest average CO AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_state = AQI_df.groupby(\"State\").mean()\n",
    "df_grouped_sorted_CO = df_grouped_state.sort_values(by=['CO AQI'], ascending = False)\n",
    "df_grouped_sorted_CO.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "CO_state_list = df_grouped_sorted_CO.head(10).index.tolist()\n",
    "CO_state_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 states with highest average NO2 AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_state = AQI_df.groupby(\"State\").mean()\n",
    "df_grouped_sorted_NO2 = df_grouped_state.sort_values(by=['NO2 AQI'], ascending = False)\n",
    "df_grouped_sorted_NO2.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NO2_state_list = df_grouped_sorted_NO2.head(10).index.tolist()\n",
    "NO2_state_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 states with highest average O3 AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_state = AQI_df.groupby(\"State\").mean()\n",
    "df_grouped_sorted_O3 = df_grouped_state.sort_values(by=['O3 AQI'], ascending = False)\n",
    "df_grouped_sorted_O3.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "O3_state_list = df_grouped_sorted_O3.head(10).index.tolist()\n",
    "O3_state_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 states with highest average SO2 AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_state = AQI_df.groupby(\"State\").mean()\n",
    "df_grouped_sorted_SO2 = df_grouped_state.sort_values(by=['SO2 AQI'], ascending = False)\n",
    "df_grouped_sorted_SO2.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "SO2_state_list = df_grouped_sorted_SO2.head(10).index.tolist() \n",
    "SO2_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#get list of states for top ten of each AQI. Remove duplicates so data is pulled once\n",
    "Top_10_AQI_list = CO_state_list + NO2_state_list + O3_state_list + SO2_state_list\n",
    "Top_10_AQI_list = set(Top_10_AQI_list)\n",
    "Top_10_AQI_list = list(Top_10_AQI_list)\n",
    "print(len(Top_10_AQI_list))\n",
    "Top_10_AQI_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull data from API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States location ID Lookup reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/locations?locationcategoryid=ST&limit=52\"\n",
    "\n",
    "headers = {\n",
    "    \"token\": API_TOKEN\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()\n",
    "#pprint(response.json())\n",
    "\n",
    "states_library = pd.DataFrame(response.json()[\"results\"])\n",
    "states_library = states_library.replace('District of Columbia', 'District Of Columbia')\n",
    "states_library = states_library[['name', 'id']]\n",
    "states_library.columns = ['State', 'Id']\n",
    "states_library.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull weather Data from API using selecrted states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = \"2007-01-01\"\n",
    "enddate = \"2016-12-31\"\n",
    "\n",
    "#url = f\"https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GSOY&startdate={startdate}&enddate={enddate}&datatypeid=TAVG&limit=1000&locationid={location}&offset={offset}\"\n",
    "\n",
    "headers = {\n",
    "    \"token\": API_TOKEN\n",
    "}\n",
    "\n",
    "weather_data = []\n",
    "\n",
    "# for state in Top_10_AQI_list:\n",
    "for state in all_states:   \n",
    "    \n",
    "    location_index = states_library[states_library['State'] == state].index.tolist()[0]\n",
    "    location = states_library['Id'][location_index]\n",
    "    \n",
    "    print(state)\n",
    "    print(location)\n",
    "    \n",
    "    url = f\"https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GSOY&startdate={startdate}&enddate={enddate}&datatypeid=TAVG&limit=1000&locationid={location}\"\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    #print(url)\n",
    "    print(response)\n",
    "    #response.json()\n",
    "    print(response.json()[\"metadata\"])\n",
    "    results = response.json()[\"results\"]\n",
    "    results_count = int(response.json()[\"metadata\"][\"resultset\"][\"count\"])\n",
    "\n",
    "    for entry in results:\n",
    "        entry['State'] = state\n",
    "    \n",
    "    #print(results)\n",
    "\n",
    "    weather_data.append(results)\n",
    "    \n",
    "    \n",
    "    if results_count > 1000:\n",
    "        adjustment = divmod(results_count, 1000)\n",
    "        print(adjustment)\n",
    "        if adjustment[1] > 0:\n",
    "            for i in range(adjustment[0]):\n",
    "#                 print(i)\n",
    "                offset = (1000*(i+1))+1\n",
    "                #print(offset)\n",
    "\n",
    "                url = url = f\"https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GSOY&startdate={startdate}&enddate={enddate}&datatypeid=TAVG&limit=1000&locationid={location}&offset={offset}\"\n",
    "                response = requests.get(url, headers=headers)\n",
    "\n",
    "                #print(url)\n",
    "                print(response)\n",
    "                #response.json()\n",
    "                #print(response.json()[\"metadata\"][\"resultset\"][\"count\"])\n",
    "                results = response.json()[\"results\"]\n",
    "                results_count = int(response.json()[\"metadata\"][\"resultset\"][\"count\"])\n",
    "\n",
    "                for entry in results:\n",
    "                    entry['State'] = state\n",
    "                    \n",
    "                weather_data.append(results)\n",
    "                \n",
    "        else:\n",
    "            for i in range(1, adjustment[0]):\n",
    "#                 print(i)\n",
    "                offset = (1000*(i))+1\n",
    "                #print(offset)\n",
    "        \n",
    "                url = url = f\"https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GSOY&startdate={startdate}&enddate={enddate}&datatypeid=TAVG&limit=1000&locationid={location}&offset={offset}\"\n",
    "                response = requests.get(url, headers=headers)\n",
    "\n",
    "                #print(url)\n",
    "                print(response)\n",
    "                #response.json()\n",
    "                #print(response.json()[\"metadata\"][\"resultset\"][\"count\"])\n",
    "                results = response.json()[\"results\"]\n",
    "                results_count = int(response.json()[\"metadata\"][\"resultset\"][\"count\"])\n",
    "\n",
    "                for entry in results:\n",
    "                    entry['State'] = state\n",
    "                    \n",
    "                weather_data.append(results)\n",
    "        \n",
    "        \n",
    "    print(\"---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_data\n",
    "weather_data2 = []\n",
    "for state in weather_data:\n",
    "    for entry in state:\n",
    "        weather_data2.append(entry)\n",
    "#weather_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame(weather_data2)\n",
    "#convert date to year\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'], format='%Y-%m-%dT%H:%M:%S').dt.year\n",
    "weather_df = weather_df.rename(columns={'date': 'Year', 'station': 'Station', 'value': 'Average_Temp'})\n",
    "weather_df = weather_df[['Year', 'Station', 'Average_Temp', 'State']]\n",
    "\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_grouped = weather_df.groupby(['State', 'Year']).mean()\n",
    "weather_df_grouped = weather_df_grouped.reset_index()\n",
    "\n",
    "columnsX = list(weather_df_grouped.columns)\n",
    "columnsX = [x.lower() for x in columnsX]\n",
    "\n",
    "weather_df_grouped.columns = columnsX\n",
    "\n",
    "weather_df_grouped['id'] = weather_df_grouped.index\n",
    "\n",
    "weather_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Data to PgAdmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql://postgres:{AWS_password}@database-1.cft8wszdkeh0.us-east-2.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "weather_df_grouped.to_sql(name=\"weather\",con=engine, if_exists=\"replace\", index=False) #Weather Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "    con.execute('ALTER TABLE \"weather\" ADD PRIMARY KEY (id);')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US States coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "      <td>32.601011</td>\n",
       "      <td>-86.680736</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>61.302501</td>\n",
       "      <td>-158.775020</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AZ</td>\n",
       "      <td>34.168219</td>\n",
       "      <td>-111.930907</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AR</td>\n",
       "      <td>34.751928</td>\n",
       "      <td>-92.131378</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.271875</td>\n",
       "      <td>-119.270415</td>\n",
       "      <td>California</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state        lat         lng        city  id\n",
       "0    AL  32.601011  -86.680736     Alabama   0\n",
       "1    AK  61.302501 -158.775020      Alaska   1\n",
       "2    AZ  34.168219 -111.930907     Arizona   2\n",
       "3    AR  34.751928  -92.131378    Arkansas   3\n",
       "4    CA  37.271875 -119.270415  California   4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV \n",
    "states_coordinates = pd.read_csv(\"Resources/datasets_772_1440_statelatlong.csv\")\n",
    "\n",
    "# Pollution in the U.S. since 2000\n",
    "states_coordinates = states_coordinates.replace('District of Columbia', 'District Of Columbia')\n",
    "\n",
    "columnsX = list(states_coordinates.columns)\n",
    "columnsX = [x.lower() for x in columnsX]\n",
    "\n",
    "states_coordinates.columns = columnsX\n",
    "states_coordinates = states_coordinates.rename(columns={\"latitude\": \"lat\", \"longitude\": \"lng\"})\n",
    "\n",
    "states_coordinates['id'] = states_coordinates.index\n",
    "\n",
    "states_coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql://postgres:{AWS_password}@database-1.cft8wszdkeh0.us-east-2.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "states_coordinates.to_sql(name=\"states_cord\",con=engine, if_exists=\"replace\", index=False) #cordinates of states Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "    con.execute('ALTER TABLE \"states_cord\" ADD PRIMARY KEY (id);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenv045806ec1b7c44efa36b1015d8efe684"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
